{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47cba2a0",
   "metadata": {},
   "source": [
    "Objective\n",
    "In this checkpoint, we'll manipulate Hadoop Pig & Hive using the knowledge acquired in this chapter, \n",
    "\n",
    "Instructions\n",
    "Hive\n",
    "\n",
    "1. Create a book table where the schema is as follows: : (id INT, title STRING, publishDate STRING)\n",
    "\n",
    "2. import data from the file /checkpoint/books/books.txt (stored locally) in the book table.\n",
    "\n",
    "3. display the records where the id is 2. \n",
    "\n",
    "4. Create a new sales table in the following HDFS location:‘/user/cloudera/checkpoint’\n",
    "\n",
    "The sales table contains 3 columns : (id INT, buyer STRING, purchaseDate STRING) \n",
    "\n",
    "5. Display 5 rows of the sales table.\n",
    "\n",
    "6. Create the table book_sale with the following fields:(id INT, title STRING, buyer STRING, purchaseDate STRING) \n",
    "\n",
    "7. Fill the book-sale table using a joint according to column id among the tables: books and sale.\n",
    "\n",
    "8. Show 10 records of the table book_sale.\n",
    "\n",
    "9. Delete book tables, sales, and book_sale.\n",
    "\n",
    "\n",
    "PIG\n",
    "\n",
    "The proposed data game is based on movies. We have two files: the list of movies and the list of arts.\n",
    "\n",
    "1. Copy the two files ‘artists.json’ and ‘movies.json’ under HDFS.\n",
    "\n",
    "2. Load the two files using JsonLoader\n",
    "\n",
    "3. Display the list of American films by year (show the year and the names of movies)\n",
    "\n",
    "4. Display each director’s list of American films\n",
    "\n",
    "5. Display the triplets (idFilm, idActeur, role)\n",
    "\n",
    "6. Display for each film the complete descriptions of its actors\n",
    "\n",
    "7. Show for each film the number of its actors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86640cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. Create a book table where the schema is as follows: : (id INT, title STRING, publishDate STRING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d7621e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CREATE TABLE book (id INT, title STRING, publishDate STRING)\n",
    "ROW FORMAT DELIMITED\n",
    "FIELDS TERMINATED BY','\n",
    "STORED AS TEXTFILE;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfd3818",
   "metadata": {},
   "outputs": [],
   "source": [
    "2. import data from the file /checkpoint/books/books.txt (stored locally) in the book table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152c9435",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD DATA LOCAL INPATH '/checkpoint/books/books.txt'\n",
    "OVERWRITE INTO TABLE book;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8041923",
   "metadata": {},
   "source": [
    "3. display the records where the id is 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b3038a",
   "metadata": {},
   "outputs": [],
   "source": [
    "select * from book where id=2;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159018a3",
   "metadata": {},
   "source": [
    "4. Create a new sales table in the following HDFS location:‘/user/cloudera/checkpoint’\n",
    "\n",
    "The sales table contains 3 columns : (id INT, buyer STRING, purchaseDate STRING) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24eb4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "CREATE EXTERNAL TABLE sales (id INT, buyer STRING, purchaseDate STRING)\n",
    "ROW FORMAT DELIMITED\n",
    "FIELDS TERMINATED BY'\\t'\n",
    "STORED AS TEXTFILE\n",
    "LOCATION '/user/cloudera/checkpoint';"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fde576b",
   "metadata": {},
   "source": [
    "5. Display 5 rows of the sales table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9047813",
   "metadata": {},
   "outputs": [],
   "source": [
    "select * from sales limit 5;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d8d39f",
   "metadata": {},
   "source": [
    "6. Create the table book_sale with the following fields:(id INT, title STRING, buyer STRING, purchaseDate STRING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5bfee03",
   "metadata": {},
   "outputs": [],
   "source": [
    "CREATE TABLE book_sale (id INT, title STRING,buyer STRING, publishDate STRING)\n",
    "ROW FORMAT DELIMITED\n",
    "FIELDS TERMINATED BY','\n",
    "STORED AS TEXTFILE;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec7f431",
   "metadata": {},
   "source": [
    "7. Fill the book-sale table using a joint according to column id among the tables: book and sale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3334335c",
   "metadata": {},
   "outputs": [],
   "source": [
    "INSERT OVERWRITE TABLE book_sale\n",
    "SELECT b.id, b.title, s.buyer, s.purchaseDate\n",
    "FROM book b JOIN sales s ON (b.id=s.id);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0da4dd",
   "metadata": {},
   "source": [
    "8. Show 10 records of the table book_sale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f283dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "select * from book_sale limit 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0296209c",
   "metadata": {},
   "source": [
    "9. Delete book tables, sales, and book_sale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d4be40",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop table book;\n",
    "drop table sales;\n",
    "drop table book_sale;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56034f2",
   "metadata": {},
   "source": [
    "PIG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52aff74",
   "metadata": {},
   "source": [
    "1.Copy the two files ‘artists.json’ and ‘movies.json’ under HDFS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be9485d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grunt>artists = LOAD 'hdfs://localhost:9000/pig_data/artists.txt' USING PigStorage(',') AS ('id: chararray, firstName:chararray,lastName:chararray, birth:chararray');\n",
    "grunt>movies = LOAD 'hdfs://localhost:9000/pig_data/artists.txt' USING PigStorage(',') AS ('id:chararray, title:chararray, year:chararray,genre:chararray, summary:chararray, country:chararray,\n",
    "                    director: (id:chararray,lastName:chararray,firstName:chararray,birthDate:chararray),actors: {(id:chararray, role:chararray)}');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f55d2d",
   "metadata": {},
   "source": [
    "2. Load the two files using JsonLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ee5011",
   "metadata": {},
   "outputs": [],
   "source": [
    "grunt>artists = LOAD 'artists-pig.json'\n",
    "      USING JsonLoader('id: chararray, firstName:chararray,lastName:chararray, birth:chararray');\n",
    "\n",
    "movies = LOAD 'movies-pig.json'\n",
    "  USING JsonLoader('id:chararray, title:chararray, year:chararray,genre:chararray, summary:chararray, country:chararray,\n",
    "                    director: (id:chararray,lastName:chararray,firstName:chararray,birthDate:chararray),\n",
    "                    actors: {(id:chararray, role:chararray)}');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f4a1cd",
   "metadata": {},
   "source": [
    "3. Display the list of American films by year (show the year and the names of movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3fc197",
   "metadata": {},
   "outputs": [],
   "source": [
    "grunt> movies = GROUP mUSA_annee BY year and country=usa;\n",
    "grunt> describe movies;\n",
    "movies: {group: chararray,\n",
    "mUSA_annee: {title:chararray}}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e260906",
   "metadata": {},
   "source": [
    "4. Display each director’s list of American films"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da744847",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = load 'webdam-movies.txt'\n",
    "as (id:chararray,lastName:chararray,firstName:chararray,year: int, title: chararray) ;\n",
    "group_direct = group movies by director;\n",
    "authors = foreach group_direct generate group, movies.director;\n",
    "dump director;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748a3fee",
   "metadata": {},
   "source": [
    "5. Display the triplets (idFilm, idActeur, role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d17b5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "grunt> triplets = GROUP actors BY idFilm;\n",
    "grunt> describe triplets;\n",
    "triplets: {group: chararray,\n",
    "actors: {(id:chararray, role:chararray)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029e2669",
   "metadata": {},
   "source": [
    "6. Display for each film the complete descriptions of its actors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f21baf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
